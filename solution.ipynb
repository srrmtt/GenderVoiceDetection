{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib.pyplot import cm\n",
    "# my libraries import \n",
    "import preprocessing as prep\n",
    "import plot as plt\n",
    "import mvg\n",
    "import utility as util\n",
    "import logistic_regression as lr\n",
    "import dcf \n",
    "import gmm \n",
    "import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = 12\n",
    "# preprocessing \n",
    "LDA = False\n",
    "PCA = False\n",
    "# enable models \n",
    "DATA_VISUALIZATION = False\n",
    "MVG = False\n",
    "LOGISTIC_REGRESSION = True\n",
    "SVM = False\n",
    "GMM = True\n",
    "DIM_REDUCTION = False\n",
    "FUSION = False\n",
    "\n",
    "# dataset path\n",
    "fileTR = './data/Train.txt'\n",
    "fileTE = './data/Train.txt'\n",
    "\n",
    "# named features \n",
    "features = [\"Feature(\" + str(x) + \")\" for x in range(N_FEATURES)]\n",
    "\n",
    "# load dataset\n",
    "DTR, LTR = prep.load_dataset(fileTR)\n",
    "DTE, LTE = prep.load_dataset(fileTE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA parameter\n",
    "m = 9 \n",
    "\n",
    "if DIM_REDUCTION: \n",
    "    if LDA:\n",
    "        print(\"---- LDA ----\")\n",
    "        DTR_lda = prep.LDA(DTR, LTR, [0,1])\n",
    "        print(\"space reducted to:\", DTR_lda.shape)\n",
    "    if PCA:\n",
    "        PCA_enabled = True\n",
    "        print(\"---- PCA with m=\", m,\" -----\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_VISUALIZATION:\n",
    "    maleDTR = DTR[:, LTR == 0]\n",
    "    femaleDTR = DTR[:, LTR == 1]\n",
    "    plt.plot_features_distr(DTR, LTR, features)\n",
    "    plt.plot_relation_beetween_feautures(DTR, LTR, features)\n",
    "    plt.plot_heatmap(DTR, features, cm.Greys)\n",
    "    plt.plot_heatmap(maleDTR, features, cm.Blues)\n",
    "    plt.plot_heatmap(femaleDTR, features, cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0  -  (12, 1500)\n",
      "fold: 1  -  (12, 1500)\n",
      "fold: 2  -  (12, 1500)\n",
      "fold: 3  -  (12, 1500)\n",
      "fold: 0  -  (12, 1500)\n",
      "fold: 1  -  (12, 1500)\n",
      "fold: 2  -  (12, 1500)\n",
      "fold: 3  -  (12, 1500)\n"
     ]
    }
   ],
   "source": [
    "# folds preparation\n",
    "applications = [(0.5, 1, 1), (0.1, 1, 1), (0.9, 1, 1)]\n",
    "# n - folds\n",
    "k = 4\n",
    "# split z-norm DTR and DTR \n",
    "foldsZ, folds_labels = prep.make_folds(DTR, LTR, k)\n",
    "folds, folds_labels = prep.make_folds(DTR, LTR, k)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MVG:\n",
    "    print(\"----- MVG full covariance -----\")\n",
    "    full_minDCFs = []\n",
    "    for application in applications:\n",
    "        pi, Cfn, Cfp = application\n",
    "        print(\"Application with (pi:\", pi,\", Cfn\",Cfn,\", Cfp\",Cfp,\")\")\n",
    "        classPriors = [pi, 1-pi]\n",
    "        llrs = util.k_folds(folds, folds_labels, k, mvg.MVG, PCA_enabled=PCA, m=m, classPriors=classPriors)\n",
    "        scores = np.hstack(llrs)\n",
    "        minDCF = dcf.compute_min_DCF(scores, np.hstack(folds_labels), pi, Cfn, Cfp)\n",
    "        full_minDCFs.append(minDCF)\n",
    "        #print(\"minDCF:\", minDCF)\n",
    "    print(\"----- MVG diagonal covariance -----\")\n",
    "    diag_minDCFs = []\n",
    "    for application in applications:\n",
    "        pi, Cfn, Cfp = application\n",
    "        print(\"Application with (pi:\", pi,\", Cfn\",Cfn,\", Cfp\",Cfp,\")\")\n",
    "        classPriors = [pi, 1-pi]\n",
    "        llrs = util.k_folds(folds, folds_labels, k, mvg.MVG, PCA_enabled=PCA, m=m, classPriors=classPriors, diag=True)\n",
    "        scores = np.hstack(llrs)\n",
    "        minDCF = dcf.compute_min_DCF(scores, np.hstack(folds_labels), pi, Cfn, Cfp)\n",
    "        diag_minDCFs.append(minDCF)\n",
    "    \n",
    "    print(\"----- MVG tied full covariance -----\")\n",
    "    tied_minDCFs = []\n",
    "    for application in applications:\n",
    "        pi, Cfn, Cfp = application\n",
    "        print(\"Application with (pi:\", pi,\", Cfn\",Cfn,\", Cfp\",Cfp,\")\")\n",
    "        classPriors = [pi, 1-pi]\n",
    "        llrs = util.k_folds(folds, folds_labels, k, mvg.MVG, PCA_enabled=PCA, m=m, classPriors=classPriors, tied=True)\n",
    "        scores = np.hstack(llrs)\n",
    "        minDCF = dcf.compute_min_DCF(scores, np.hstack(folds_labels), pi, Cfn, Cfp)\n",
    "        tied_minDCFs.append(minDCF)\n",
    "    \n",
    "    print(\"----- MVG tied digonal covariance -----\")\n",
    "    tied_diag_minDCFs = []\n",
    "    for application in applications:\n",
    "        pi, Cfn, Cfp = application\n",
    "        print(\"Application with (pi:\", pi,\", Cfn\",Cfn,\", Cfp\",Cfp,\")\")\n",
    "        classPriors = [pi, 1-pi]\n",
    "        llrs = util.k_folds(folds, folds_labels, k, mvg.MVG, PCA_enabled=PCA, m=m, classPriors=classPriors, diag=True, tied=True)\n",
    "        scores = np.hstack(llrs)\n",
    "        minDCF = dcf.compute_min_DCF(scores, np.hstack(folds_labels), pi, Cfn, Cfp)\n",
    "        tied_diag_minDCFs.append(minDCF)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lambda_ = 10**-6\n",
    "if LOGISTIC_REGRESSION:\n",
    "    print(\"\\n\\n----- Linear logistic regression -----\")\n",
    "    classPriors = [0.5, 0.5]\n",
    "    STE = util.k_folds(folds, folds_labels, k, lr.logreg, priors=classPriors, lambda_ = lambda_)\n",
    "    scoresLR = np.hstack(STE)\n",
    "    plt.plot_min_DCF_logreg(folds, folds_labels, k, applications, quadratic=False)\n",
    "    for application in applications:\n",
    "        pi, Cfn, Cfp = application\n",
    "        l = 10e-6\n",
    "        print(\"Application with ( pi:\", pi,\", Cfn:\",Cfn,\", Cfp:\",Cfp,\")\")\n",
    "        for pi_T in [0.5, 0.1, 0.9]:\n",
    "            print(\"\\tevaluating with pi_T:\", pi_T)\n",
    "            classPriors = [pi_T, 1-pi_T]\n",
    "            STE = util.k_folds(folds, folds_labels, k, lr.logreg, priors=classPriors, lambda_ = lambda_)\n",
    "            scores = np.hstack(STE)\n",
    "            minDCF = dcf.compute_min_DCF(scores, np.hstack(folds_labels), pi, Cfn, Cfp)\n",
    "            #print(\"minDCF:\", minDCF)\n",
    "    print(\"------ Quadratic Logistic Regression ------\")\n",
    "    plt.plot_min_DCF_logreg(folds, folds_labels, k, applications, quadratic=True)\n",
    "    for application in [applications[2]]:\n",
    "        pi = application[0]\n",
    "        Cfn = application[1]\n",
    "        Cfp = application[2]\n",
    "        \n",
    "        print(\"Application with ( pi:\", pi,\", Cfn:\",Cfn,\", Cfp:\",Cfp,\")\")\n",
    "        for pi_T in [0.5, 0.1, 0.9]:\n",
    "            print(\"\\tevaluating with pi_T:\", pi_T)\n",
    "            classPriors = [pi_T, 1-pi_T]\n",
    "            STE = util.k_folds(folds, folds_labels, k, lr.quadratic_logreg, priors=classPriors, lambda_ = lambda_)\n",
    "            scores = np.hstack(STE)\n",
    "            minDCF = dcf.compute_min_DCF(scores, np.hstack(folds_labels), pi, Cfn, Cfp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SVM: \n",
    "    print(\"\\n\\n----- linear SVM -----\")\n",
    "    plt.plot_min_DCF_svm(folds, folds_labels, k, applications, balanced=True)\n",
    "\n",
    "    for application in applications:\n",
    "        pi, Cfn, Cfp = application\n",
    "        print(\"application:\", application)\n",
    "        for pi_T in [0.5, 0.1, 0.9]:\n",
    "            print(\"\\tevaluating with pi_T:\", pi_T)\n",
    "            classPriors = [pi_T, 1-pi_T]\n",
    "            scores = util.k_folds(folds, folds_labels, k, svm.train_SVM_linear, C = 1)\n",
    "            scores = np.hstack(scores)\n",
    "            minDCF = dcf.compute_min_DCF(scores, np.hstack(folds_labels), pi, Cfn, Cfp)\n",
    "\n",
    "    print(\"----- Exponential SVM ----\")\n",
    "    gammas = [0.1, 0.01, 0.001]\n",
    "    plt.plot_min_DCF_RBFsvm(folds, folds_labels, k, gammas)\n",
    "\n",
    "    for application in applications:\n",
    "        pi, Cfn, Cfp = application\n",
    "        print(\"application:\", application)\n",
    "        for pi_T in [0.5, 0.1, 0.9]:\n",
    "            print(\"\\tevaluating with pi_T:\", pi_T)\n",
    "            classPriors = [pi_T, 1-pi_T]\n",
    "            scores = util.k_folds(folds, folds_labels, k, svm.train_non_linear_SVM, kernel='rbf', C=0.10, gamma=0.01, balanced=True, priors=classPriors)\n",
    "            scores = np.hstack(scores)\n",
    "            \n",
    "            minDCF = dcf.compute_min_DCF(scores, np.hstack(folds_labels), pi, Cfn, Cfp)\n",
    "\n",
    "    print(\"----- Quadratic SVM ----\")\n",
    "    plt.plot_min_DCF_poly_svm(folds, folds_labels, k, applications)\n",
    "    scores = util.k_folds(folds, folds_labels, k, svm.train_non_linear_SVM, kernel='poly', C=0.1, d=2.0, c=1)\n",
    "    scores = np.hstack(scores)\n",
    "    for application in applications:\n",
    "        pi, Cfn, Cfp = application\n",
    "        print(\"application:\", application)\n",
    "        minDCF = dcf.compute_min_DCF(scores, np.hstack(folds_labels), pi, Cfn, Cfp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM (Gaussian Multivariate Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1 \n",
    "stopping_criterion = 1e-6\n",
    "# number of components (2^G - 1)\n",
    "G = 4\n",
    "psi = 0.01 \n",
    "if GMM:\n",
    "    print(\"\\n\\n----- GMM Classifier -----\")\n",
    "    print(\"\\tFull Covariance - Non Tied Cvoariances\")\n",
    "    \n",
    "\n",
    "    plot_name = f\"gmm-{2**(G-1)}-full-nonTied\"\n",
    "    folds_component_llrs = util.k_folds(folds, folds_labels, k, gmm.GMM, PCA_enabled, None, preprocessing=False,\n",
    "                        alpha=alpha, stopping_criterion=stopping_criterion, G=G, psi=psi, full_cov=True, tied=False )\n",
    "    minDCFsRaw = dcf.GMM_minDCF(folds_component_llrs, folds_labels, G, k, applications[0])\n",
    "    folds_component_llrs = util.k_folds(folds, folds_labels, k, gmm.GMM, PCA_enabled, None, preprocessing=True,\n",
    "                        alpha=alpha, stopping_criterion=stopping_criterion, G=G, psi=psi, full_cov=True, tied=False )\n",
    "    minDCFsZ = dcf.GMM_minDCF(folds_component_llrs, folds_labels, G, k, applications[0])\n",
    "    \n",
    "    \n",
    "    plt.plot_minDCF_GMM_hist(minDCFsRaw, minDCFsZ, G, plot_name)\n",
    "    \n",
    "    # Full covariance --- tied model\n",
    "    plot_name = f\"gmm-{2**(G-1)}-full-tied\"\n",
    "    folds_component_llrs = util.k_folds(folds, folds_labels, k, gmm.GMM, PCA_enabled, None, preprocessing=False,\n",
    "                        alpha=alpha, stopping_criterion=stopping_criterion, G=G, psi=psi, full_cov=True, tied=True )\n",
    "    minDCFsRaw = dcf.GMM_minDCF(folds_component_llrs, folds_labels, G, k, applications[0])\n",
    "    folds_component_llrs = util.k_folds(folds, folds_labels, k, gmm.GMM, PCA_enabled, None, preprocessing=True,\n",
    "                        alpha=alpha, stopping_criterion=stopping_criterion, G=G, psi=psi, full_cov=True, tied=True )\n",
    "    minDCFsZ = dcf.GMM_minDCF(folds_component_llrs, folds_labels, G, k, applications[0])\n",
    "    plt.plot_minDCF_GMM_hist(minDCFsRaw, minDCFsZ, G, plot_name)\n",
    "    \n",
    "    # Diag Covariance - Non Tied\n",
    "    plot_name = f\"gmm-{2**(G-1)}-diag-nonTied\"\n",
    "    folds_component_llrs = util.k_folds(folds, folds_labels, k, gmm.GMM, PCA_enabled, None, preprocessing=False,\n",
    "                        alpha=alpha, stopping_criterion=stopping_criterion, G=G, psi=psi, full_cov=False, tied=False )\n",
    "    minDCFsRaw = dcf.GMM_minDCF(folds_component_llrs, folds_labels, G, k, applications[0])\n",
    "    folds_component_llrs = util.k_folds(folds, folds_labels, k, gmm.GMM, PCA_enabled, None, preprocessing=True,\n",
    "                        alpha=alpha, stopping_criterion=stopping_criterion, G=G, psi=psi, full_cov=False, tied=False )\n",
    "    minDCFsZ = dcf.GMM_minDCF(folds_component_llrs, folds_labels, G, k, applications[0])\n",
    "    plt.plot_minDCF_GMM_hist(minDCFsRaw, minDCFsZ, G, plot_name)\n",
    "    \n",
    "    # Diag Covariance - Tied\n",
    "    plot_name = f\"gmm-{2**(G-1)}-diag-tied\"\n",
    "    folds_component_llrs = util.k_folds(folds, folds_labels, k, gmm.GMM, PCA_enabled, None, preprocessing=False,\n",
    "                        alpha=alpha, stopping_criterion=stopping_criterion, G=G, psi=psi, full_cov=False, tied=True )\n",
    "    minDCFsRaw = dcf.GMM_minDCF(folds_component_llrs, folds_labels, G, k, applications[0])\n",
    "    folds_component_llrs = util.k_folds(folds, folds_labels, k, gmm.GMM, PCA_enabled, None, preprocessing=True,\n",
    "                        alpha=alpha, stopping_criterion=stopping_criterion, G=G, psi=psi, full_cov=False, tied=True )\n",
    "    minDCFsZ = dcf.GMM_minDCF(folds_component_llrs, folds_labels, G, k, applications[0])\n",
    "    plt.plot_minDCF_GMM_hist(minDCFsRaw, minDCFsZ, G, plot_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FUSION:\n",
    "    scores, labels = lr.score_fusion(scoresLR, scoresMVG,  np.hstack(folds_labels), [0.5, 0.5])\n",
    "    print(scores.shape)\n",
    "    minDCF = dcf.compute_min_DCF(scores.ravel(), labels, 0.5, 1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
